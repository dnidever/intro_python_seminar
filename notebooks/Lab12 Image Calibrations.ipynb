{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12: Image Calibrations\n",
    "Based on the astropy tutorial http://docs.astropy.org/en/stable/io/fits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import ZScaleInterval\n",
    "# change some default plotting parameters\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['image.origin'] = 'lower'\n",
    "mpl.rcParams['image.cmap'] = 'Greys_r'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Correction\n",
    "Here is a simple image correction based on our discussions from Chapter 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist = fits.open('data/aa_aql0007_raw.fits')\n",
    "image_data = hdulist[0].data\n",
    "image_hdr = hdulist[0].header\n",
    "interval = ZScaleInterval()\n",
    "(imin,imax) = interval.get_limits(image_data)\n",
    "plt.imshow(image_data, vmin=imin,vmax=imax)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Combination\n",
    "The first step is to combine our calibration frames to make a master calibration. I have 10 biases named `bias001.fits` through `bias010.fits`. Let's use a median combine. We will create a list of bias frames, and give the combined frame the same header as the first frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biaslist = list()\n",
    "for i in np.arange(10) + 1:\n",
    "    #Append each bias frame into our list\n",
    "    filename = 'data/bias{:03d}.fits'.format(i)\n",
    "    print(filename)\n",
    "    biaslist.append(fits.open(filename)[0].data)\n",
    "\n",
    "#Create a 3-d data cube\n",
    "data_cube = np.array(biaslist)\n",
    "print(data_cube.shape)\n",
    "\n",
    "#Now median the images together along the first axis\n",
    "combined_data = np.median(data_cube,axis=0)\n",
    "print(combined_data.shape)\n",
    "\n",
    "#Take image header from first bias\n",
    "combined_hdr = fits.open('data/bias001.fits')[0].header\n",
    "#Add a keyword, so we know this is a combined frame\n",
    "combined_hdr['NCOMBINE'] = 10\n",
    "fits.writeto('data/Zero.fits', combined_data, combined_hdr,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imin,imax) = interval.get_limits(combined_data)\n",
    "plt.imshow(combined_data, vmin=imin,vmax=imax)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Subtraction\n",
    "The first step is to remove a bias (zeroes) from our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = fits.open('data/Zero.fits')\n",
    "bias_data = bias[0].data\n",
    "step1 = image_data - bias_data\n",
    "print(image_data[61,60])\n",
    "print(step1[61,60])\n",
    "image_hdr['comment'] = \"Subtracted Bias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imin,imax) = interval.get_limits(step1)\n",
    "plt.imshow(step1, vmin=imin,vmax=imax)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dark Subtraction\n",
    "Step 2 is Dark Subtraction (Note each Calibration image has already had the previous step applied to it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark = fits.open('data/Dark.fits')\n",
    "dark_hdr = dark[0].header\n",
    "dark_data = dark[0].data\n",
    "(imin,imax) = interval.get_limits(dark_data)\n",
    "plt.imshow(dark_data, vmin=imin,vmax=imax)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2 = step1 - dark_data\n",
    "image_hdr['comment'] = \"Subtracted Dark\"\n",
    "print(image_data[61,60])\n",
    "print(step1[61,60])\n",
    "print(step2[61,60]) #Uh-Oh something is wrong?\n",
    "(imin,imax) = interval.get_limits(step2)\n",
    "plt.imshow(step2, vmin=imin,vmax=imax)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_hdr['exptime'])\n",
    "print(dark_hdr['exptime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also need to know the dark current.\n",
    "dark_current = np.median(dark_data/(dark_hdr['exptime']))\n",
    "print(dark_current)\n",
    "#Save Dark Current in header\n",
    "image_hdr['DARKCUR'] = (dark_current,\"Dark Current ADU per second\")\n",
    "\n",
    "#Need to correct scale the dark to the exposure time of the science frame\n",
    "step2 = step1 - (dark_data * (image_hdr['exptime']/dark_hdr['exptime']))\n",
    "print(image_data[61,60])\n",
    "print(step1[61,60])\n",
    "print(step2[61,60]) #Much Better\n",
    "(imin,imax) = interval.get_limits(step2)\n",
    "plt.imshow(step2, vmin=imin,vmax=imax)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat Fielding\n",
    "Step 3 is to Flat Field the image. This is a normalization so we are dividing instead of subtracting. `FlatV.fits` is a combined Flat taken in the V filter. It has had both the Zero and Dark removed already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = fits.open('data/FlatV.fits')\n",
    "flat_hdr = flat[0].header\n",
    "flat_data = flat[0].data\n",
    "(imin,imax) = interval.get_limits(flat_data)\n",
    "plt.imshow(flat_data, vmin=imin,vmax=imax)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(flat_data)) #Is the median level of our Flat\n",
    "step3 = step2 / flat_data\n",
    "image_hdr['comment'] = \"Divided Flat\"\n",
    "print(image_data[61,60])\n",
    "print(step1[61,60])\n",
    "print(step2[61,60]) #Much Better\n",
    "print(step3[61,60]) #Hmmm this is a little strange\n",
    "(imin,imax) = interval.get_limits(step3)\n",
    "plt.imshow(step3, vmin=imin,vmax=imax)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your results\n",
    "You can save your results by giving the function fits.writeto() your data and an optional header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.writeto('data/out.fits', step3, image_hdr,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 12: Now it is your turn\n",
    "Please answer the following questions, then print them off and turn them in. You don't need to print the whole notebook. Only print the pages starting from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1: In /data there is a formally reduced image called `aa_aql0007.fits`. Compare it to your image `out.fits`. How good a job did we do?**\n",
    "* Open both images in ds9\n",
    "* Print the header of out.fits\n",
    "* Print fits info about both images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2: Try the following:**\n",
    "* Plot both images\n",
    "* Print the min, max, and median of both images \n",
    "* Divide both images and plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3: Divide both images. Print the min, max, and median of the resulting image. Plot the resulting image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4: Clearly we forgot something in Step 3. Redo Step 3, so that it gives the correct count level for the final image. Print the min, max, and median of the corrected image. Plot the corrected image. Hint: Chapter 9 will give you guidance on this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
